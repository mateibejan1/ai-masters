{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Project 1: Automatic Grading of Multiple Choice Tests\n",
    "\n",
    "### Author: Matei Bejan, group 407"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "model14 = keras.models.load_model('14_recognizer.h5')\n",
    "model_digit1 = keras.models.load_model('digit1recognizer.h5')\n",
    "model_digit2 = keras.models.load_model('digit2recognizer.h5')\n",
    "    \n",
    "possible_grades = [1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4.0, 4.3, 4.6, 4.9, 5.2, 5.5, \n",
    "                   5.8, 6.1, 6.4, 6.7, 7.0, 7.3, 7.6, 7.9, 8.2, 8.5, 8.8, 9.1, 9.4, 9.7, 10.0]\n",
    "    \n",
    "grade_map = {4.9: 12, 6.7: 10, 5.8: 8, 8.5: 3, 9.1: 2, 3.7: 3, 5.5: 16, 4.6: 8, 7.3: 10, 6.4: 17,\n",
    "             7.0: 7, 7.6: 8, 6.1: 7, 7.9: 4, 8.8: 8, 5.2: 8, 9.7: 2, 8.2: 2, 4.3: 8, 9.4: 2, 4.0: 5}\n",
    "\n",
    "alpha2digit = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "\n",
    "reference_scan = cv.imread('1_reference_scanned.png')\n",
    "reference_rotated = cv.imread('2_reference_rotated.png')\n",
    "reference_perspective = cv.imread('3_reference_perspective.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_folder = 'images/'\n",
    "\n",
    "# images = glob.glob(os.path.join(base_folder, \"image_*.jpg\"))\n",
    "# images = sorted(images, key = lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "# image_truths = glob.glob(os.path.join(base_folder, \"image_*.txt\"))\n",
    "# image_truths = sorted(image_truths, key = lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "# rotations = glob.glob(os.path.join(base_folder, \"rotation_*.jpg\"))\n",
    "# rotations = sorted(rotations, key = lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "# perspectives = glob.glob(os.path.join(base_folder, \"perspective_*.jpg\"))\n",
    "# perspectives = sorted(perspectives, key = lambda x: int(x.split('_')[1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_map = {'F1': ['Fizica', '1'], 'F2': ['Fizica', '2'], \n",
    "               'F3': ['Fizica', '3'], 'F4': ['Fizica', '4'], \n",
    "               'I1': ['Informatica', '1'], 'I2': ['Informatica', '2'], \n",
    "               'I3': ['Informatica', '3'], 'I4': ['Informatica', '4']}\n",
    "\n",
    "scanned_images = glob.glob(\"test_data/1.scanned/*.jpg\")\n",
    "scanned_images = sorted(scanned_images, key = lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "rotated_images = glob.glob(\"test_data/2.rotated+perspective/*_rotated_*.jpg\")\n",
    "rotated_images = sorted(rotated_images, key = lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "perspective_images = glob.glob(\"test_data/2.rotated+perspective/*_perspective_*.jpg\")\n",
    "perspective_images = sorted(perspective_images, key = lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "nanot_images = glob.glob(\"test_data/3.no_annotation/*.jpg\")\n",
    "nanot_images = sorted(nanot_images, key = lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "hw_images = glob.glob(\"test_data/4.handwritten/*.jpg\")\n",
    "hw_images = sorted(hw_images, key = lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "ground_truths = glob.glob(\"ground-truth-correct-answers/*.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_upper_checkbox(img):\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    img = img[int(0.442 * orig_h):int(0.5 * orig_h), int(0.83 * orig_w):int(0.9 * orig_w)]\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    box = cv.adaptiveThreshold(gray, \n",
    "                               255, \n",
    "                               cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv.THRESH_BINARY_INV, \n",
    "                               101, 3)\n",
    "    h,w = box.shape\n",
    "    box = np.rot90(box, 2)\n",
    "    i = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 0:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box, 2)\n",
    "    box = box[:h-i,:]\n",
    "    h,w = box.shape\n",
    "    h1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            h1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            w2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    h2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            h2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            w1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    box = box[h1:h-h2,w1:w-w2]\n",
    "    h, w = box.shape\n",
    "    h1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            h1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            w2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    h2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            h2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            w1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    box = box[h1:h-h2,w1:w-w2]\n",
    "    return box.copy()\n",
    "\n",
    "def crop_lower_checkbox(img):\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    img = img[int(0.48 * orig_h):int(0.54 * orig_h), int(0.83 * orig_w):int(0.9 * orig_w)].copy()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    box =  cv.adaptiveThreshold(gray, \n",
    "                                255, \n",
    "                                cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                cv.THRESH_BINARY_INV, \n",
    "                                101, 3)\n",
    "    h,w = box.shape\n",
    "    i = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 0:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    box = box[i:,:]\n",
    "    box = np.rot90(box, 2)\n",
    "    h, w = box.shape\n",
    "    i = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 0:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box, 2)\n",
    "    box = box[:h-i,:]\n",
    "    h,w = box.shape\n",
    "    h1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            h1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            w2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    h2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            h2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) < 50:\n",
    "            w1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    box = box[h1:h-h2,w1:w-w2]\n",
    "    h, w = box.shape\n",
    "    h1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            h1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            w2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    h2 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            h2 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    w1 = 0\n",
    "    for row in box:\n",
    "        if np.mean(row) > 100:\n",
    "            w1 += 1\n",
    "        else:\n",
    "            break\n",
    "    box = np.rot90(box)\n",
    "    box = box[h1:h-h2,w1:w-w2]\n",
    "    return box.copy()\n",
    "\n",
    "def crop_left_table(img):\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    return img[int(0.525 * orig_h):int(0.87 * orig_h), int(0.2 * orig_w):int(0.38 * orig_w)].copy()\n",
    "\n",
    "def crop_right_table(img):\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    return img[int(0.525 * orig_h):int(0.87 * orig_h), int(0.73 * orig_w):int(0.9 * orig_w)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_lines(image):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    binary = cv.adaptiveThreshold(gray, \n",
    "                                  255, \n",
    "                                  cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv.THRESH_BINARY_INV, \n",
    "                                  301, 25)\n",
    "\n",
    "    lines = cv.HoughLinesP(binary,\n",
    "                           cv.HOUGH_PROBABILISTIC, \n",
    "                           np.pi / 180, \n",
    "                           threshold = 150, \n",
    "                           minLineLength = 150,\n",
    "                           maxLineGap = 10)\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0][0] != line[0][2] and (line[0][0] >= line[0][2] - 25 and line[0][0] <= line[0][2] + 25):\n",
    "            line[0][2] = line[0][0]\n",
    "    \n",
    "    vertical_all = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0][0] == line[0][2]:\n",
    "            vertical_all.append(line.tolist()[0])\n",
    "            \n",
    "    vertical_lines = []\n",
    "\n",
    "    for line in vertical_all:\n",
    "        if line not in vertical_all:\n",
    "            vertical_lines.append(line)\n",
    "        else:\n",
    "            flag = False\n",
    "            for line2 in vertical_lines:\n",
    "                if not flag and line[0] - 50 <= line2[0] and line2[0] <= line[0] + 50:\n",
    "                     flag = True\n",
    "            if not flag:\n",
    "                vertical_lines.append([line[0], 0, line[0], image.shape[0]])\n",
    "                \n",
    "    lines = sorted(vertical_lines, key=lambda line: line[0])\n",
    "        \n",
    "    return lines[:5]\n",
    "\n",
    "def get_horizontal_lines(image):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    binary = cv.adaptiveThreshold(gray, \n",
    "                                  255, \n",
    "                                  cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                  cv.THRESH_BINARY_INV, \n",
    "                                  301, 25)\n",
    "\n",
    "    lines = cv.HoughLinesP(binary,\n",
    "                           cv.HOUGH_PROBABILISTIC, \n",
    "                           np.pi / 180, \n",
    "                           threshold = 150, \n",
    "                           minLineLength = 150,\n",
    "                           maxLineGap = 50)\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0][1] != line[0][3] and (line[0][1] >= line[0][3] - 25 and line[0][1] <= line[0][3] + 25):\n",
    "            line[0][3] = line[0][1]\n",
    "\n",
    "    horizontal_all = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line[0][1] == line[0][3] and line[0][1] > 10:\n",
    "            horizontal_all.append(line.tolist()[0])\n",
    "            \n",
    "    horizontal_lines = []\n",
    "\n",
    "    for line in horizontal_all:\n",
    "        if line not in horizontal_all:\n",
    "            horizontal_lines.append(line)\n",
    "        else:\n",
    "            flag = False\n",
    "            for line2 in horizontal_lines:\n",
    "                if flag == False and line[1] - 50 <= line2[1] and line2[1] <= line[1] + 50:\n",
    "                     flag = True\n",
    "            if flag == False:\n",
    "                horizontal_lines.append([0, line[1], image.shape[1], line[3]])\n",
    "           \n",
    "    lines = sorted(horizontal_lines, key=lambda line: line[1], reverse = True)\n",
    "    \n",
    "    lines = lines[:16]\n",
    "    \n",
    "    lines.reverse()\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_from_images(input_image):\n",
    "    vertical_lines = get_vertical_lines(input_image)\n",
    "    horizontal_lines = get_horizontal_lines(input_image)\n",
    "    \n",
    "    grayscale_image = cv.cvtColor(input_image, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    image = np.dstack((grayscale_image, grayscale_image, grayscale_image))\n",
    "    x_color = (0, 255, 0) \n",
    "    blank_color = (0, 0, 255)\n",
    "    \n",
    "    # No ticks? Multiple ticks on the same row? Check the list's length!\n",
    "    answer = {1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], \n",
    "              9: [], 10: [], 11: [], 12: [], 13: [], 14: [], 15: []}\n",
    "            \n",
    "    patch_means = []\n",
    "    \n",
    "    for i in range(len(horizontal_lines) - 1):\n",
    "        for j in range(len(vertical_lines) - 1):\n",
    "            maxx = horizontal_lines[i + 1][1] - horizontal_lines[i][1]\n",
    "            maxy = vertical_lines[j + 1][0] - vertical_lines[j][0]\n",
    "            x_min = horizontal_lines[i][1] + maxx // 3\n",
    "            x_max = horizontal_lines[i + 1][1] - maxx // 4\n",
    "            y_min = vertical_lines[j][0] + maxy // 4\n",
    "            y_max = vertical_lines[j + 1][0] - maxy // 4\n",
    "    \n",
    "            patch = grayscale_image[x_min:x_max, y_min:y_max].copy()\n",
    "            \n",
    "            patch = cv.adaptiveThreshold(patch, \n",
    "                                         255, \n",
    "                                         cv.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                         cv.THRESH_BINARY, \n",
    "                                         21, 20)\n",
    "            \n",
    "            patch_means.append(np.round(patch.mean()))\n",
    "\n",
    "    threshold = np.round(np.array(patch_means).mean())\n",
    "\n",
    "    for i in range(len(horizontal_lines) - 1):\n",
    "        for j in range(len(vertical_lines) - 1):\n",
    "            maxx = horizontal_lines[i + 1][1] - horizontal_lines[i][1]\n",
    "            maxy = vertical_lines[j + 1][0] - vertical_lines[j][0]\n",
    "            x_min = horizontal_lines[i][1] + maxx // 3\n",
    "            x_max = horizontal_lines[i + 1][1] - maxx // 4\n",
    "            y_min = vertical_lines[j][0] + maxy // 4\n",
    "            y_max = vertical_lines[j + 1][0] - maxy // 4\n",
    "                \n",
    "            patch = grayscale_image[x_min:x_max, y_min:y_max].copy()\n",
    "            \n",
    "            patch = cv.adaptiveThreshold(patch, \n",
    "                                         255, \n",
    "                                         cv.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                         cv.THRESH_BINARY, \n",
    "                                         21, 20)\n",
    "            \n",
    "            mean_patch_value = np.round(patch.mean())\n",
    "            \n",
    "            if mean_patch_value <= threshold:\n",
    "                color = x_color\n",
    "                answer[i + 1].append(j + 1)\n",
    "            else:\n",
    "                color = blank_color\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(image_to_translate, \n",
    "                 image_reference, \n",
    "                 max_features = 10000,\n",
    "                 good_match_percent = .1):\n",
    "\n",
    "    img1_gray = cv.cvtColor(image_to_translate, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(image_reference, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv.ORB_create(max_features)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
    "    \n",
    "    matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    nr_good_matches = int(len(matches) * good_match_percent)\n",
    "    matches = matches[:nr_good_matches]\n",
    "\n",
    "    img_matches = cv.drawMatches(image_to_translate, \n",
    "                                 keypoints1, \n",
    "                                 image_reference, \n",
    "                                 keypoints2, \n",
    "                                 matches, None)\n",
    "\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "    height, width, channels = image_reference.shape\n",
    "    img_reg = cv.warpPerspective(image_to_translate, h, (width, height))\n",
    "\n",
    "    return img_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option(image):\n",
    "    upper = crop_upper_checkbox(image)\n",
    "    lower = crop_lower_checkbox(image)\n",
    "        \n",
    "    if np.mean(upper) > np.mean(lower):\n",
    "        upper = cv.resize(upper, (28, 28))\n",
    "        return ('Informatica', np.argmax(model14.predict(upper.reshape(1, 28, 28, 1))))\n",
    "    elif np.mean(upper) < np.mean(lower):\n",
    "        lower = cv.resize(lower, (28, 28))\n",
    "        return ('Fizica', np.argmax(model14.predict(lower.reshape(1, 28, 28, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### 1. Real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task1_output = open('output/matei_bejan_407_task1.txt', 'a')\n",
    "\n",
    "for image_path in scanned_images:\n",
    "    image = cv.imread(image_path)\n",
    "    right_table = crop_right_table(image)\n",
    "    left_table = crop_left_table(image)\n",
    "    \n",
    "    answers_left = find_x_from_images(left_table)\n",
    "    answers_right = find_x_from_images(right_table)\n",
    "    \n",
    "    option = options_map[image_path.split('/')[-1].split('_')[-1][:2]]\n",
    "    \n",
    "    ground_truth_path = None\n",
    "    ground_truth = {}\n",
    "    i = 0\n",
    "    while ground_truth_path == None:\n",
    "        if option[0] in ground_truths[i].split('/')[-1] \\\n",
    "        and str(option[1]) in ground_truths[i].split('/')[-1]:\n",
    "            ground_truth_path = ground_truths[i]\n",
    "        i += 1\n",
    "\n",
    "    file1 = open(ground_truth_path, 'r') \n",
    "    Lines = file1.readlines() \n",
    "    for line in Lines: \n",
    "        line = line.split(' ')\n",
    "        if line[0].isnumeric() and line[0] not in ground_truth:\n",
    "            ground_truth[int(line[0])] = [alpha2digit[line[1][0]]]\n",
    "                \n",
    "    count_correct = 0\n",
    "\n",
    "    for i in range(1, 16):\n",
    "        if len(answers_left[i]) == 1 and answers_left[i][0] == ground_truth[i][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    for i1, i2 in list(zip(range(1, 16), range(16, 31))):\n",
    "        if len(answers_right[i1]) == 1 and answers_right[i1][0] == ground_truth[i2][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    grade = 0.3 * count_correct + 1\n",
    "    sgr = str(grade)\n",
    "    if len(sgr) > 3 and sgr[3] == '9':\n",
    "        grade = float(sgr[:2] + str(int(sgr[2]) + 1))\n",
    "        \n",
    "    task1_output.write(image_path.split('/')[-1] + ' ' + str(grade) + '\\n')\n",
    "    \n",
    "task1_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task2_output = open('output/matei_bejan_407_task2.txt', 'a')\n",
    "\n",
    "for image_path in rotated_images:\n",
    "    image = cv.imread(image_path)\n",
    "    aligned = align_images(align_images(image, reference_rotated), reference_scan)\n",
    "    \n",
    "    right_table = crop_right_table(aligned)\n",
    "    left_table = crop_left_table(aligned)\n",
    "    \n",
    "    answers_left = find_x_from_images(left_table)\n",
    "    answers_right = find_x_from_images(right_table)\n",
    "    \n",
    "    option = options_map[image_path.split('/')[-1].split('_')[-1][:2]]\n",
    "    ground_truth_path = None\n",
    "    ground_truth = {}\n",
    "    i = 0\n",
    "    while ground_truth_path == None:\n",
    "        if option[0] in ground_truths[i].split('/')[-1] \\\n",
    "        and str(option[1]) in ground_truths[i].split('/')[-1]:\n",
    "            ground_truth_path = ground_truths[i]\n",
    "        i += 1\n",
    "\n",
    "    file1 = open(ground_truth_path, 'r') \n",
    "    Lines = file1.readlines() \n",
    "    for line in Lines: \n",
    "        line = line.split(' ')\n",
    "        if line[0].isnumeric() and line[0] not in ground_truth:\n",
    "            ground_truth[int(line[0])] = [alpha2digit[line[1][0]]]\n",
    "                \n",
    "    count_correct = 0\n",
    "\n",
    "    for i in range(1, 16):\n",
    "        if len(answers_left[i]) == 1 and answers_left[i][0] == ground_truth[i][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    for i1, i2 in list(zip(range(1, 16), range(16, 31))):\n",
    "        if len(answers_right[i1]) == 1 and answers_right[i1][0] == ground_truth[i2][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    grade = 0.3 * count_correct + 1\n",
    "    sgr = str(grade)\n",
    "    if len(sgr) > 3 and sgr[3] == '9':\n",
    "        grade = float(sgr[:2] + str(int(sgr[2]) + 1))\n",
    "\n",
    "    task2_output.write(image_path.split('/')[-1] + ' ' + str(grade) + '\\n')\n",
    "    \n",
    "task2_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task2_output = open('output/matei_bejan_407_task2.txt', 'a')\n",
    "\n",
    "for image_path in perspective_images:\n",
    "    image = cv.imread(image_path)\n",
    "    aligned = align_images(align_images(align_images(image, \n",
    "                                                     reference_perspective, 10000, 0.15), \n",
    "                                        reference_rotated), \n",
    "                           reference_scan)\n",
    "    \n",
    "    right_table = crop_right_table(aligned)\n",
    "    left_table = crop_left_table(aligned)\n",
    "    \n",
    "    answers_left = find_x_from_images(left_table)\n",
    "    answers_right = find_x_from_images(right_table)\n",
    "    \n",
    "    option = options_map[image_path.split('/')[-1].split('_')[-1][:2]]\n",
    "    \n",
    "    ground_truth_path = None\n",
    "    ground_truth = {}\n",
    "    i = 0\n",
    "    while ground_truth_path == None:\n",
    "        if option[0] in ground_truths[i].split('/')[-1] \\\n",
    "        and str(option[1]) in ground_truths[i].split('/')[-1]:\n",
    "            ground_truth_path = ground_truths[i]\n",
    "        i += 1\n",
    "\n",
    "    file1 = open(ground_truth_path, 'r') \n",
    "    Lines = file1.readlines() \n",
    "    for line in Lines: \n",
    "        line = line.split(' ')\n",
    "        if line[0].isnumeric() and line[0] not in ground_truth:\n",
    "            ground_truth[int(line[0])] = [alpha2digit[line[1][0]]]\n",
    "                \n",
    "    count_correct = 0\n",
    "\n",
    "    for i in range(1, 16):\n",
    "        if len(answers_left[i]) == 1 and answers_left[i][0] == ground_truth[i][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    for i1, i2 in list(zip(range(1, 16), range(16, 31))):\n",
    "        if len(answers_right[i1]) == 1 and answers_right[i1][0] == ground_truth[i2][0]:\n",
    "            count_correct += 1\n",
    "\n",
    "    grade = 0.3 * count_correct + 1\n",
    "    sgr = str(grade)\n",
    "    if len(sgr) > 3 and sgr[3] == '9':\n",
    "        grade = float(sgr[:2] + str(int(sgr[2]) + 1))\n",
    "\n",
    "    task2_output.write(image_path.split('/')[-1] + ' ' + str(grade) + '\\n')\n",
    "    \n",
    "task2_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. No annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task3_output = open('output/matei_bejan_407_task3.txt', 'a')\n",
    "\n",
    "for image_path in nanot_images:\n",
    "    image = cv.imread(image_path)\n",
    "    if np.mean(image) < 230:\n",
    "        aligned = align_images(align_images(align_images(image, \n",
    "                                                         reference_perspective, 10000, .15), \n",
    "                                            reference_rotated), \n",
    "                               reference_scan)\n",
    "    else:\n",
    "        aligned = image\n",
    "        \n",
    "    right_table = crop_right_table(aligned)\n",
    "    left_table = crop_left_table(aligned)\n",
    "    \n",
    "    answers_left = find_x_from_images(left_table)\n",
    "    answers_right = find_x_from_images(right_table)\n",
    "    \n",
    "    option = get_option(aligned)\n",
    "\n",
    "    if option != None:\n",
    "        ground_truth_path = None\n",
    "        ground_truth = {}\n",
    "        i = 0\n",
    "        while ground_truth_path == None:\n",
    "            if option[0] in ground_truths[i].split('/')[-1] \\\n",
    "            and str(option[1]) in ground_truths[i].split('/')[-1]:\n",
    "                ground_truth_path = ground_truths[i]\n",
    "            i += 1\n",
    "\n",
    "        file1 = open(ground_truth_path, 'r') \n",
    "        Lines = file1.readlines() \n",
    "        for line in Lines: \n",
    "            line = line.split(' ')\n",
    "            if line[0].isnumeric() and line[0] not in ground_truth:\n",
    "                ground_truth[int(line[0])] = [alpha2digit[line[1][0]]]\n",
    "\n",
    "        count_correct = 0\n",
    "\n",
    "        for i in range(1, 16):\n",
    "            if len(answers_left[i]) == 1 and answers_left[i][0] == ground_truth[i][0]:\n",
    "                count_correct += 1\n",
    "\n",
    "        for i1, i2 in list(zip(range(1, 16), range(16, 31))):\n",
    "            if len(answers_right[i1]) == 1 and answers_right[i1][0] == ground_truth[i2][0]:\n",
    "                count_correct += 1\n",
    "\n",
    "        grade = 0.3 * count_correct + 1\n",
    "        sgr = str(grade)\n",
    "        if len(sgr) > 3 and sgr[3] == '9':\n",
    "            grade = float(sgr[:2] + str(int(sgr[2]) + 1))\n",
    "\n",
    "        task3_output.write(image_path.split('/')[-1] + ' ' + str(grade) + '\\n')\n",
    "    else:\n",
    "        task3_output.write(image_path.split('/')[-1] + '6.4\\n')\n",
    "        \n",
    "task3_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Handwritten recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task4_output = open('output/matei_bejan_407_task4.txt', 'a')\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for image_path in hw_images:\n",
    "    image = cv.imread(image_path)\n",
    "    orig_h, orig_w, _ = image.shape\n",
    "    image = image[int(0.29 * orig_h):int(0.33 * orig_h), int(0.09 * orig_w):int(0.153 * orig_w)]\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    lower = np.array([170,50,50])\n",
    "    upper = np.array([180,255,255])\n",
    "    mask = cv.inRange(image, lower, upper)\n",
    "    mask = cv.GaussianBlur(mask, (7, 7), 1)\n",
    "    mask2 = []\n",
    "    mask = np.rot90(mask)\n",
    "    for line in mask:\n",
    "        if np.mean(line) > 0:\n",
    "            mask2.append(line)\n",
    "    mask = np.array(mask2)\n",
    "    mask2 = []\n",
    "    mask = np.rot90(mask)\n",
    "    for line in mask:\n",
    "        if np.mean(line) > 0:\n",
    "            mask2.append(line)\n",
    "    mask = np.array(mask2)\n",
    "    mask2 = []\n",
    "    mask = np.rot90(mask)\n",
    "    for line in mask:\n",
    "        if np.mean(line) > 0:\n",
    "            mask2.append(line)\n",
    "    mask = np.array(mask2)\n",
    "    mask = np.rot90(mask)\n",
    "\n",
    "    h, w = mask.shape\n",
    "    fp = mask[:,:w // 3 + 5]\n",
    "    sp = mask[:,w // 2 - 10:]\n",
    "    sp = sp[:,:w // 2 + 10]\n",
    "    fp = cv.resize(fp, (28, 28))\n",
    "    fp = np.expand_dims(fp, 2)\n",
    "    sp = cv.resize(sp, (28, 28))\n",
    "    sp = np.expand_dims(sp, 2)\n",
    "    \n",
    "    p1 = np.argmax(model_digit1.predict(fp.reshape(1, 28, 28, 1)))\n",
    "    p2 = np.argmax(model_digit2.predict(sp.reshape(1, 28, 28, 1)))\n",
    "\n",
    "    predicted_grade = float(p1 * 10 + p2) / 10\n",
    "    if predicted_grade <= 1:\n",
    "        predicted_grade = 6.4\n",
    "    elif predicted_grade not in possible_grades:\n",
    "        first_digit = int(str(predicted_grade)[0])\n",
    "        second_digit = None\n",
    "        maxi = 0\n",
    "        for key, val in grade_map.items():\n",
    "            if int(str(key)[0]) == first_digit and val > maxi:\n",
    "                maxi = val\n",
    "                second_digit = int(str(key)[2])\n",
    "        predicted_grade = float(first_digit * 10 + second_digit) / 10\n",
    "\n",
    "    task4_output.write(image_path.split('/')[-1] + ' ' + str(predicted_grade) + '\\n')\n",
    "        \n",
    "task4_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
